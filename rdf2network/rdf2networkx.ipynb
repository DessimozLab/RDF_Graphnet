{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZJA7QRc-lnW"
   },
   "outputs": [],
   "source": [
    "# Install required packages in the current Jupyter kernel\n",
    "# Uncomment the following lines if you need to install these libraries\n",
    "# If you run into permission issues, try with the --user option\n",
    "#import sys\n",
    "#!pip install -q rdflib networkx matplotlib\n",
    "#!{sys.executable} -m pip install rdflib networkx matplotlib pandas stringdb --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sampler\n",
    "import grabhogs_sparql\n",
    "import map2string_fast\n",
    "import addfrombloom\n",
    "import rdflib\n",
    "import SPARQLWrapper\n",
    "import colour\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aVA-JNpI-lna",
    "outputId": "a418ca78-5317-4b62-9367-642d64e2c709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdflib Graph loaded successfully with 2620310 triples\n",
      "rdflib Graph loaded successfully with 14559 triples\n"
     ]
    }
   ],
   "source": [
    "datapath = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.links.rdf.v11.5/402676.protein.links.rdf.v11.5.txt.gz'\n",
    "# RDF graph loading\n",
    "rg = sampler.load_graph(datapath)\n",
    "\n",
    "datapath2 = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.info.rdf.v11.5/402676.protein.info.rdf.v11.5.txt.gz'\n",
    "# RDF graph loading\n",
    "rg_info  = sampler.load_graph(datapath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831\n"
     ]
    }
   ],
   "source": [
    "links = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.links.rdf.v11.5/*.protein.links.rdf.v11.5.txt.gz'\n",
    "linkfiles = glob.glob(links)\n",
    "linkfiles = { l:{ 'links':l , 'info':l.replace('protein.links' , 'protein.info' ) } for l in linkfiles}\n",
    "print(len(linkfiles ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://string-db.org/network/402676.B6K0F0\n"
     ]
    }
   ],
   "source": [
    "subjs = rg.subjects( unique = True)\n",
    "seed = next(subjs)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 656\n",
      "{rdflib.term.URIRef('https://string-db.org/rdf/high-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/any-confidence'), rdflib.term.URIRef('https://string-db.org/rdf/medium-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/highest-confidence-cutoff')}\n",
      "rdflib Graph sampled successfully with 551 triples\n"
     ]
    }
   ],
   "source": [
    "subg = sampler.sample( rg = rg , seed = seed,  layer_limit= 2 , sample_run = 20 )\n",
    "print(set([p for p in subg.predicates()]))\n",
    "print(\"rdflib Graph sampled successfully with {} triples\".format(len(subg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aVA-JNpI-lna",
    "outputId": "a418ca78-5317-4b62-9367-642d64e2c709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "83\n",
      "rdflib Graph annotated successfully with 634 triples\n",
      "{rdflib.term.URIRef('https://string-db.org/rdf/highest-confidence-cutoff'), rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot'), rdflib.term.URIRef('https://string-db.org/rdf/medium-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/high-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/any-confidence')}\n",
      "https://string-db.org/network/402676.B6JVH1 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JVH1\n",
      "https://string-db.org/network/402676.B6JWV4 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JWV4\n",
      "https://string-db.org/network/402676.B6JVX3 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JVX3\n",
      "https://string-db.org/network/402676.B6JWG8 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JWG8\n",
      "https://string-db.org/network/402676.B6JW85 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JW85\n",
      "https://string-db.org/network/402676.B6JZF7 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JZF7\n",
      "https://string-db.org/network/402676.B6JVM3 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JVM3\n",
      "https://string-db.org/network/402676.B6JVA4 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JVA4\n",
      "https://string-db.org/network/402676.B6JVV0 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JVV0\n",
      "https://string-db.org/network/402676.B6JUY4 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JUY4\n",
      "https://string-db.org/network/402676.B6K3S5 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K3S5\n"
     ]
    }
   ],
   "source": [
    "subg = sampler.add_xrefs( rg_info , subg )\n",
    "print(\"rdflib Graph annotated successfully with {} triples\".format(len(subg)))\n",
    "print(set([p for p in subg.predicates()]))\n",
    "cross_ref = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\")\n",
    "i = 0 \n",
    "for s,p,o in subg.triples((None, cross_ref, None)):\n",
    "    print(s,p,o)\n",
    "    i+= 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proteins_by_species , results_subj_para , results_subj_ortho  = grabhogs_sparql.grab_hogs( subg , cross_ref = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results_subj_ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "Total time for 166 SPARQL queries: 80.63025951385498 seconds (multiple batch calls in: 0 cases)\n",
      "Num errors: 0\n"
     ]
    }
   ],
   "source": [
    "orthograph =  grabhogs_sparql.grab_hogs_graph( subg , cross_ref , sparql_endpoint= None\n",
    "            , USE_CASE = 1 , verbose = True , cross_ref_prop = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdflib Graph annotated successfully with 1324517 triples\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "print(\"rdflib Graph annotated successfully with {} triples\".format(len(orthograph)))\n",
    "#get all species\n",
    "taxa = [ 'protein1_uniprot_taxon_orth' , 'protein1_uniprot_taxon_para']\n",
    "species = set( [ o for t in taxa  for s,p,o in orthograph.triples((None, URIRef(t), None))  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the results for that species\n",
    "taxa = [ 'orth_protein_uniprot_taxon_orth' , 'para_protein_uniprot_taxon_para']\n",
    "#get all proteins for each species\n",
    "prots_by_species = { spec: set([s  for s,p,o in orthograph.triples((None, URIRef(t), spec ))]) for t in taxa for spec in species  }\n",
    "prots_by_species = { spec:prots_by_species[spec] for spec in prots_by_species if len(prots_by_species[spec])   }\n",
    "prots_by_species = { spec:[ p.replace('http://purl.uniprot.org/uniprot/' , '' ) for p in prots_by_species[spec] ] for spec in prots_by_species }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'dna076'\n",
    "ortho_xrefgraph = map2string_fast.mapall(prots_by_species , serverurl= \"http://\"+server+\":3030/string_fuseki/sparql\" , retgraph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthograph += ortho_xrefgraph\n",
    "subg += orthograph\n",
    "#we have interactions for one species and ortho info to all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = addfrombloom.load_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets add the interactions for all using the bloom filters\n",
    "print( len(orthograph ) , set([p for p in orthograph.predicates() ]) )\n",
    "#get string ids by species\n",
    "pred = rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot')\n",
    "interactions = []\n",
    "for spec in prots_by_species:\n",
    "    stringids = [ s for prot in prots_by_species[spec] for s,p,o in orthograph.triples((None, pred , URIRef('http://purl.uniprot.org/uniprot/'+prot) )) ]\n",
    "    stringids = [ s.replace('https://string-db.org/network/' , '' ) for s in stringids ]\n",
    "    \n",
    "    if len(stringids ) > 2 :\n",
    "        interactions += addfrombloom.check_allvall( objects = stringids , urlstring = 'https://string-db.org/network/' , filters = filters )\n",
    "[subg.add(t) for t in interactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#halelujah we have a graph with everything in it\n",
    "#serialize to turtle format\n",
    "v = subg.serialize(format=\"ttl\")\n",
    "with open('testgraph.ttl', 'w') as graphout:\n",
    "    graphout.write(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subg))\n",
    "readg = Graph()\n",
    "readg.parse('testgraph.ttl')\n",
    "print(len(readg))\n",
    "#we can save the subgraphs in rdf...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new heterodata object\n",
    "from torch_geometric.data import HeteroData , Data\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.utils \n",
    "from rdflib import RDF\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import torch\n",
    "\n",
    "\n",
    "def sparse2pairs(sparsemat, matrows = None):\n",
    "    '''\n",
    "    This functino takes a sparse matrix and returns a list of pairs of the non zero entries\n",
    "    args:\n",
    "        sparsemat: a sparse matrix\n",
    "        matrows: a list of the matrix rows to keep\n",
    "    Returns:    \n",
    "        a list of pairs of the non zero entries\n",
    "    '''\n",
    "    if matrows :\n",
    "        sparsemat = sparsemat[matrows,:]\n",
    "        sparsemat = sparsemat[:,matrows]\n",
    "    sparsemat = scipy.sparse.find(sparsemat)\n",
    "    return np.vstack([sparsemat[0],sparsemat[1]])\n",
    "\n",
    "def test_heterograph(rdf_graph , verbose = True):\n",
    "    data = HeteroData()\n",
    "    # assign edge types from the predicate\n",
    "    edge_types = set([p for s,p,o in rdf_graph])\n",
    "    edge_types = {e:i for i,e in enumerate(edge_types)}\n",
    "    uris = {}\n",
    "    subtypes = {}\n",
    "    for sub, pred, obj in rdf_graph:\n",
    "        for o in (sub,obj):\n",
    "            if isinstance(o, URIRef):\n",
    "                uri_type = rdf_graph.qname(o).split(\":\")[0]  # get the namespace prefix\n",
    "                if uri_type not in uris:\n",
    "                    uris[uri_type] = []\n",
    "                    subtypes[uri_type] = set([])\n",
    "                uris[uri_type].append(o)\n",
    "                subtypes[uri_type].add( ''.join(o.n3().split('/')[0:-1] )  )\n",
    "    if verbose == True:\n",
    "        for t in subtypes:\n",
    "            #compile the x data matrix for each subtype\n",
    "            subtype_dict = { ty:i for i,ty in enumerate(subtypes[t])}\n",
    "            indices = [ subtype_dict[''.join(o.n3().split('/')[0:-1])] for o in uris[t] ]\n",
    "            x= np.zeros( (len(uris[t]), len(subtype_dict)))\n",
    "            x[:,indices] = 1\n",
    "            #for now this is 1hot for subtype\n",
    "            #add some more descriptive data here if you have it\n",
    "            data[t].x = torch.tensor(x , dtype=torch.float )\n",
    "    node_index_by_type = { uritype : { n:i for i,n in enumerate( set(uris[uritype]) ) } for uritype in uris }\n",
    "    #todo add the diff types of uris within each namespace as 1hot encoded for x attribute of each node\n",
    "    for t1,t2 in itertools.product(node_index_by_type,node_index_by_type):\n",
    "            rows = node_index_by_type[t1]\n",
    "            columns = node_index_by_type[t2]\n",
    "            if verbose == True:\n",
    "                print(t1,len(rows),t2, len(columns)) \n",
    "                \n",
    "            for edge_type in edge_types:\n",
    "                \n",
    "                # create a dictionary of nodes\n",
    "                \n",
    "                triples =  [ (s,p,o) for s,p,o in rdf_graph.triples((None, edge_type, None))  if ( s in rows and o in columns )  ]\n",
    "                \n",
    "                if len(triples)>0:\n",
    "                    adj = scipy.sparse.lil_matrix((len(rows), len(columns)))\n",
    "                    for s,p,o in triples:    \n",
    "                        adj[rows[s], columns[o]] = 1\n",
    "                    if verbose == True:\n",
    "                        print(adj.sum())\n",
    "                        pass\n",
    "                    #between subgraphs\n",
    "                    data[ t1 , p.n3() , t2 ].edge_index = torch.tensor( sparse2pairs(adj) ,  dtype=torch.long )\n",
    "                    if t1 == t2:\n",
    "                        #within a subgraph of the same namespace\n",
    "                        data[ t1 , p.n3() , t2 ].edge_index  = torch_geometric.utils.add_self_loops(data[ t1 , p.n3() , t2 ].edge_index )\n",
    "    data = T.ToUndirected()(data)\n",
    "    return data\n",
    "data = test_heterograph(subg)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
