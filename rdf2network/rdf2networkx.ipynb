{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sZJA7QRc-lnW"
   },
   "outputs": [],
   "source": [
    "# Install required packages in the current Jupyter kernel\n",
    "# Uncomment the following lines if you need to install these libraries\n",
    "# If you run into permission issues, try with the --user option\n",
    "#import sys\n",
    "#!pip install -q rdflib networkx matplotlib\n",
    "#!{sys.executable} -m pip install rdflib networkx matplotlib pandas stringdb --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sampler\n",
    "import grabhogs_sparql\n",
    "import map2string_fast\n",
    "import addfrombloom\n",
    "import rdflib\n",
    "import SPARQLWrapper\n",
    "import colour\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aVA-JNpI-lna",
    "outputId": "a418ca78-5317-4b62-9367-642d64e2c709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdflib Graph loaded successfully with 2620310 triples\n",
      "rdflib Graph loaded successfully with 14559 triples\n"
     ]
    }
   ],
   "source": [
    "datapath = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.links.rdf.v11.5/402676.protein.links.rdf.v11.5.txt.gz'\n",
    "# RDF graph loading\n",
    "rg = sampler.load_graph(datapath)\n",
    "\n",
    "datapath2 = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.info.rdf.v11.5/402676.protein.info.rdf.v11.5.txt.gz'\n",
    "# RDF graph loading\n",
    "rg_info  = sampler.load_graph(datapath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831\n"
     ]
    }
   ],
   "source": [
    "links = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.links.rdf.v11.5/*.protein.links.rdf.v11.5.txt.gz'\n",
    "linkfiles = glob.glob(links)\n",
    "linkfiles = { l:{ 'links':l , 'info':l.replace('protein.links' , 'protein.info' ) } for l in linkfiles}\n",
    "print(len(linkfiles ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://string-db.org/network/402676.B6JXJ9\n"
     ]
    }
   ],
   "source": [
    "subjs = rg.subjects( unique = True)\n",
    "seed = next(subjs)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 632\n",
      "{rdflib.term.URIRef('https://string-db.org/rdf/any-confidence'), rdflib.term.URIRef('https://string-db.org/rdf/highest-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/medium-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/high-confidence-cutoff')}\n",
      "rdflib Graph sampled successfully with 558 triples\n"
     ]
    }
   ],
   "source": [
    "subg = sampler.sample( rg = rg , seed = seed,  layer_limit= 2 , sample_run = 20 )\n",
    "print(set([p for p in subg.predicates()]))\n",
    "print(\"rdflib Graph sampled successfully with {} triples\".format(len(subg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aVA-JNpI-lna",
    "outputId": "a418ca78-5317-4b62-9367-642d64e2c709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "115\n",
      "rdflib Graph annotated successfully with 673 triples\n",
      "{rdflib.term.URIRef('https://string-db.org/rdf/any-confidence'), rdflib.term.URIRef('https://string-db.org/rdf/highest-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/medium-confidence-cutoff'), rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot'), rdflib.term.URIRef('https://string-db.org/rdf/high-confidence-cutoff')}\n",
      "https://string-db.org/network/402676.B6K054 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K054\n",
      "https://string-db.org/network/402676.B6JXV0 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JXV0\n",
      "https://string-db.org/network/402676.B6JWM1 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JWM1\n",
      "https://string-db.org/network/402676.B6JUT4 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JUT4\n",
      "https://string-db.org/network/402676.B6K091 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K091\n",
      "https://string-db.org/network/402676.B6JX60 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JX60\n",
      "https://string-db.org/network/402676.B6JW45 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JW45\n",
      "https://string-db.org/network/402676.B6JXB8 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JXB8\n",
      "https://string-db.org/network/402676.B6K7F6 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K7F6\n",
      "https://string-db.org/network/402676.B6JW75 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JW75\n",
      "https://string-db.org/network/402676.B6JZT0 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JZT0\n"
     ]
    }
   ],
   "source": [
    "subg = sampler.add_xrefs( rg_info , subg )\n",
    "print(\"rdflib Graph annotated successfully with {} triples\".format(len(subg)))\n",
    "print(set([p for p in subg.predicates()]))\n",
    "cross_ref = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\")\n",
    "i = 0 \n",
    "for s,p,o in subg.triples((None, cross_ref, None)):\n",
    "    print(s,p,o)\n",
    "    i+= 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proteins_by_species , results_subj_para , results_subj_ortho  = grabhogs_sparql.grab_hogs( subg , cross_ref = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results_subj_ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 230 SPARQL queries: 94.49965596199036 seconds (multiple batch calls in: 0 cases)\n",
      "Num errors: 1\n"
     ]
    }
   ],
   "source": [
    "orthograph =  grabhogs_sparql.grab_hogs_graph( subg , cross_ref , sparql_endpoint= None\n",
    "            , USE_CASE = 1 , verbose = True , cross_ref_prop = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdflib Graph annotated successfully with 1663698 triples\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "print(\"rdflib Graph annotated successfully with {} triples\".format(len(orthograph)))\n",
    "#get all species\n",
    "taxa = [ 'protein1_uniprot_taxon_orth' , 'protein1_uniprot_taxon_para']\n",
    "species = set( [ o for t in taxa  for s,p,o in orthograph.triples((None, URIRef(t), None))  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the results for that species\n",
    "taxa = [ 'orth_protein_uniprot_taxon_orth' , 'para_protein_uniprot_taxon_para']\n",
    "#get all proteins for each species\n",
    "prots_by_species = { spec: set([s  for s,p,o in orthograph.triples((None, URIRef(t), spec ))]) for t in taxa for spec in species  }\n",
    "prots_by_species = { spec:prots_by_species[spec] for spec in prots_by_species if len(prots_by_species[spec])   }\n",
    "prots_by_species = { spec:[ p.replace('https://string-db.org/network/' , '' ) for p in prots_by_species[spec] ] for spec in prots_by_species }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'dna071'\n",
    "ortho_xrefgraph = map2string_fast.mapall(prots_by_species , serverurl= \"http://\"+server+\":3030/string_fuseki/sparql\" , retgraph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthograph += ortho_xrefgraph\n",
    "subg += orthograph\n",
    "#we have interactions for one species and ortho info to all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = addfrombloom.load_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663698 {rdflib.term.URIRef('protein1_orth_protein'), rdflib.term.URIRef('taxon_para_protein_uniprot'), rdflib.term.URIRef('protein1_para_protein_uniprot'), rdflib.term.URIRef('orth_protein_uniprot_taxon_orth'), rdflib.term.URIRef('protein1_taxon'), rdflib.term.URIRef('protein1_uniprot_taxon_orth'), rdflib.term.URIRef('protein1_protein1_uniprot'), rdflib.term.URIRef('taxon_orth_protein'), rdflib.term.URIRef('protein1_uniprot_para_protein_uniprot'), rdflib.term.URIRef('protein1_uniprot_taxon_para'), rdflib.term.URIRef('protein1_uniprot_taxon'), rdflib.term.URIRef('protein1_taxon_orth'), rdflib.term.URIRef('taxon_taxon_orth'), rdflib.term.URIRef('orth_protein_orth_protein_uniprot'), rdflib.term.URIRef('para_protein_para_protein_uniprot'), rdflib.term.URIRef('protein1_uniprot_orth_protein_uniprot'), rdflib.term.URIRef('para_protein_taxon_para'), rdflib.term.URIRef('protein1_uniprot_orth_protein'), rdflib.term.URIRef('taxon_taxon_para'), rdflib.term.URIRef('taxon_orth_protein_uniprot'), rdflib.term.URIRef('protein1_uniprot_para_protein'), rdflib.term.URIRef('para_protein_uniprot_taxon_para'), rdflib.term.URIRef('taxon_para_protein'), rdflib.term.URIRef('protein1_taxon_para'), rdflib.term.URIRef('protein1_para_protein'), rdflib.term.URIRef('orth_protein_taxon_orth'), rdflib.term.URIRef('protein1_orth_protein_uniprot')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets add the interactions for all using the bloom filters\n",
    "print( len(orthograph ) , set([p for p in orthograph.predicates() ]) )\n",
    "#get string ids by species\n",
    "pred = rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot')\n",
    "interactions = []\n",
    "for spec in prots_by_species:\n",
    "    stringids = [ s for prot in prots_by_species[spec] for s,p,o in orthograph.triples((None, pred , prot )) ]\n",
    "    #stringids = [ s.replace('https://string-db.org/network/' , '' ) for s in stringids ]\n",
    "    if len(stringids ) > 2 :\n",
    "        interactions += addfrombloom.check_allvall( objects = stringids , urlstring = 'https://string-db.org/network/' , filters = filters )\n",
    "[subg.add(t) for t in interactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#halelujah we have a graph with everything in it\n",
    "#serialize to turtle format\n",
    "v = subg.serialize(format=\"ttl\")\n",
    "with open('testgraph.ttl', 'w') as graphout:\n",
    "    graphout.write(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subg))\n",
    "readg = Graph()\n",
    "readg.parse('testgraph.ttl')\n",
    "print(len(readg))\n",
    "#we can save the subgraphs in rdf...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new heterodata object\n",
    "from torch_geometric.data import HeteroData , Data\n",
    "\n",
    "def test_heterograph(rdf_graph):\n",
    "    data = HeteroData()\n",
    "    # assign edge types from the predicate\n",
    "    edge_types = set([p for s,p,o in rdf_graph])\n",
    "    edge_types = {e:i for i,e in enumerate(edge_types)}\n",
    "\n",
    "    ex_ns = rdf_graph.namespace_manager.namespaces()\n",
    "    #find all subject and object types in the namespace\n",
    "    types = [ t for type_uri in ex_ns ]\n",
    "    #create and index for all of the objects with each type\n",
    "\n",
    "    node_index_by_type = {}\n",
    "    for t in types:\n",
    "        node_index_by_type[t] = { tup[0]:i for i,tup in enumerate(rdf_graph.triples(( None , RDF.type, t) ) ) }\n",
    "\n",
    "\n",
    "    for edge_type in edge_types:\n",
    "        for t1,t2 in itertools.product(node_index_by_type,node_index_by_type):\n",
    "                # create a dictionary of nodes\n",
    "                rows = node_index_by_type[t1]\n",
    "                columns = node_index_by_type[t2]\n",
    "                triples =  [ (s,p,o) if rdf_graph.triples((None, edge_type, None)) if s.type == t1 and o.type == t2 ]\n",
    "\n",
    "                if len(rows>0) and len(columns>0):\n",
    "                    adj = scipy.sparse.lil_matrix( shape = (len(rows), len(columns)))\n",
    "                    [ adj[rows[s], columns[o]] = 1 for s,p,o in ]\n",
    "\n",
    "\n",
    "                    data[ stype.n3() , p.n3() , otype.n3() ].edge_index = from_scipy_sparse_matrix(adj)\n",
    "                    \n",
    "    return data\n",
    "\n",
    "data = test_heterograph(subg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = rdflib.extras.external_graph_libs.rdflib_to_networkx_multidigraph( subg , lambda s, p, o: {'data':{'key':p  , 'weight':1} } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "uniprot_id = \"http://purl.uniprot.org/uniprot/A0A3B5R6M3\" \n",
    "serverurl = '\n",
    "results =  map2string_fast.map2string_SPARQL(uniprot_id , serverurl = )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [ p for p in rg.predicates( unique = True)]\n",
    "red = colour.Color('red')\n",
    "blue = colour.Color('blue')\n",
    "c = [ c.hex_l for c in  list(red.range_to(blue, len(preds))) ]\n",
    "colors = { p:c[i] for i,p in enumerate(preds)}\n",
    "delta = 2/len(preds)\n",
    "curve = { p:delta*i for i,p in enumerate(preds) }\n",
    "style = itertools.cycle([ '-', '--' ])\n",
    "line_style = { p:next(style) for p in preds }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.circular_layout( G )\n",
    "f = plt.figure()\n",
    "f.set_figwidth(15)\n",
    "f.set_figheight(15)\n",
    "plt.plot()\n",
    "#plot the whole mess\n",
    "ax = plt.gca()\n",
    "for e in G.edges(data = True):\n",
    "    ax.annotate(\"\",\n",
    "                xy=pos[e[0]], xycoords='data',\n",
    "                xytext=pos[e[1]], textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"-\", color=colors[e[2]['data']['key']],\n",
    "                                shrinkA=5, shrinkB=5, lw = e[2]['data']['weight'], ls = line_style[e[2]['data']['key']],\n",
    "                                patchA=None, patchB=None, alpha = e[2]['data']['weight'],\n",
    "                                connectionstyle=\"arc3,rad=rrr\".replace('rrr',str(0.3*curve[e[2]['data']['key']])\n",
    "                                ),\n",
    "                                ),\n",
    "                )\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color = 'b', node_size = 150, alpha = .5)\n",
    "labels=nx.draw_networkx_labels(G , pos = pos , font_size= 15 , font_color='w')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map string neighbours to OMA entries\n",
    "\n",
    "#jump a few steps in HOGs\n",
    "\n",
    "#fish for STRING interactions in other species\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
