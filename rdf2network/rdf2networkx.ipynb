{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sZJA7QRc-lnW"
   },
   "outputs": [],
   "source": [
    "# Install required packages in the current Jupyter kernel\n",
    "# Uncomment the following lines if you need to install these libraries\n",
    "# If you run into permission issues, try with the --user option\n",
    "#import sys\n",
    "#!pip install -q rdflib networkx matplotlib\n",
    "#!{sys.executable} -m pip install rdflib networkx matplotlib pandas stringdb --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sampler\n",
    "import grabhogs_sparql\n",
    "import map2string_fast\n",
    "import addfrombloom\n",
    "import rdflib\n",
    "import SPARQLWrapper\n",
    "import colour\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aVA-JNpI-lna",
    "outputId": "a418ca78-5317-4b62-9367-642d64e2c709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdflib Graph loaded successfully with 2620310 triples\n",
      "rdflib Graph loaded successfully with 14559 triples\n"
     ]
    }
   ],
   "source": [
    "datapath = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.links.rdf.v11.5/402676.protein.links.rdf.v11.5.txt.gz'\n",
    "# RDF graph loading\n",
    "rg = sampler.load_graph(datapath)\n",
    "\n",
    "datapath2 = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.info.rdf.v11.5/402676.protein.info.rdf.v11.5.txt.gz'\n",
    "# RDF graph loading\n",
    "rg_info  = sampler.load_graph(datapath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831\n"
     ]
    }
   ],
   "source": [
    "links = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.links.rdf.v11.5/*.protein.links.rdf.v11.5.txt.gz'\n",
    "linkfiles = glob.glob(links)\n",
    "linkfiles = { l:{ 'links':l , 'info':l.replace('protein.links' , 'protein.info' ) } for l in linkfiles}\n",
    "print(len(linkfiles ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://string-db.org/network/402676.B6K4T6\n"
     ]
    }
   ],
   "source": [
    "subjs = rg.subjects( unique = True)\n",
    "seed = next(subjs)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 704\n",
      "{rdflib.term.URIRef('https://string-db.org/rdf/any-confidence'), rdflib.term.URIRef('https://string-db.org/rdf/highest-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/medium-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/high-confidence-cutoff')}\n",
      "rdflib Graph sampled successfully with 596 triples\n"
     ]
    }
   ],
   "source": [
    "subg = sampler.sample( rg = rg , seed = seed,  layer_limit= 2 , sample_run = 20 )\n",
    "print(set([p for p in subg.predicates()]))\n",
    "print(\"rdflib Graph sampled successfully with {} triples\".format(len(subg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aVA-JNpI-lna",
    "outputId": "a418ca78-5317-4b62-9367-642d64e2c709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "57\n",
      "rdflib Graph annotated successfully with 653 triples\n",
      "{rdflib.term.URIRef('https://string-db.org/rdf/any-confidence'), rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot'), rdflib.term.URIRef('https://string-db.org/rdf/highest-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/medium-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/high-confidence-cutoff')}\n",
      "https://string-db.org/network/402676.B6JVA8 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JVA8\n",
      "https://string-db.org/network/402676.B6JV67 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JV67\n",
      "https://string-db.org/network/402676.B6JUU0 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JUU0\n",
      "https://string-db.org/network/402676.B6JWW4 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JWW4\n",
      "https://string-db.org/network/402676.B6K038 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K038\n",
      "https://string-db.org/network/402676.B6JYQ4 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JYQ4\n",
      "https://string-db.org/network/402676.B6JYD1 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JYD1\n",
      "https://string-db.org/network/402676.B6JXV0 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JXV0\n",
      "https://string-db.org/network/402676.B6K4A8 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K4A8\n",
      "https://string-db.org/network/402676.B6JVA4 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JVA4\n",
      "https://string-db.org/network/402676.B6JXG0 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JXG0\n"
     ]
    }
   ],
   "source": [
    "subg = sampler.add_xrefs( rg_info , subg )\n",
    "print(\"rdflib Graph annotated successfully with {} triples\".format(len(subg)))\n",
    "print(set([p for p in subg.predicates()]))\n",
    "cross_ref = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\")\n",
    "i = 0 \n",
    "for s,p,o in subg.triples((None, cross_ref, None)):\n",
    "    print(s,p,o)\n",
    "    i+= 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proteins_by_species , results_subj_para , results_subj_ortho  = grabhogs_sparql.grab_hogs( subg , cross_ref = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results_subj_ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "Total time for 114 SPARQL queries: 40.11890888214111 seconds (multiple batch calls in: 0 cases)\n",
      "Num errors: 0\n"
     ]
    }
   ],
   "source": [
    "orthograph =  grabhogs_sparql.grab_hogs_graph( subg , cross_ref , sparql_endpoint= None\n",
    "            , USE_CASE = 1 , verbose = True , cross_ref_prop = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdflib Graph annotated successfully with 684998 triples\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "print(\"rdflib Graph annotated successfully with {} triples\".format(len(orthograph)))\n",
    "#get all species\n",
    "taxa = [ 'protein1_uniprot_taxon_orth' , 'protein1_uniprot_taxon_para']\n",
    "species = set( [ o for t in taxa  for s,p,o in orthograph.triples((None, URIRef(t), None))  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the results for that species\n",
    "taxa = [ 'orth_protein_uniprot_taxon_orth' , 'para_protein_uniprot_taxon_para']\n",
    "#get all proteins for each species\n",
    "prots_by_species = { spec: set([s  for s,p,o in orthograph.triples((None, URIRef(t), spec ))]) for t in taxa for spec in species  }\n",
    "prots_by_species = { spec:prots_by_species[spec] for spec in prots_by_species if len(prots_by_species[spec])   }\n",
    "prots_by_species = { spec:[ p.replace('https://string-db.org/network/' , '' ) for p in prots_by_species[spec] ] for spec in prots_by_species }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'dna071'\n",
    "ortho_xrefgraph = map2string_fast.mapall(prots_by_species , serverurl= \"http://\"+server+\":3030/string_fuseki/sparql\" , retgraph = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthograph += ortho_xrefgraph\n",
    "subg += orthograph\n",
    "#we have interactions for one species and ortho info to all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = addfrombloom.load_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684998 {rdflib.term.URIRef('taxon_taxon_para'), rdflib.term.URIRef('protein1_orth_protein_uniprot'), rdflib.term.URIRef('taxon_para_protein_uniprot'), rdflib.term.URIRef('protein1_uniprot_orth_protein_uniprot'), rdflib.term.URIRef('protein1_uniprot_taxon_para'), rdflib.term.URIRef('protein1_taxon_para'), rdflib.term.URIRef('orth_protein_orth_protein_uniprot'), rdflib.term.URIRef('taxon_para_protein'), rdflib.term.URIRef('protein1_orth_protein'), rdflib.term.URIRef('protein1_uniprot_taxon_orth'), rdflib.term.URIRef('taxon_taxon_orth'), rdflib.term.URIRef('taxon_orth_protein_uniprot'), rdflib.term.URIRef('para_protein_taxon_para'), rdflib.term.URIRef('protein1_uniprot_taxon'), rdflib.term.URIRef('orth_protein_uniprot_taxon_orth'), rdflib.term.URIRef('protein1_taxon'), rdflib.term.URIRef('protein1_taxon_orth'), rdflib.term.URIRef('protein1_para_protein_uniprot'), rdflib.term.URIRef('orth_protein_taxon_orth'), rdflib.term.URIRef('protein1_protein1_uniprot'), rdflib.term.URIRef('para_protein_uniprot_taxon_para'), rdflib.term.URIRef('taxon_orth_protein'), rdflib.term.URIRef('protein1_uniprot_para_protein_uniprot'), rdflib.term.URIRef('protein1_uniprot_para_protein'), rdflib.term.URIRef('protein1_para_protein'), rdflib.term.URIRef('protein1_uniprot_orth_protein'), rdflib.term.URIRef('para_protein_para_protein_uniprot')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets add the interactions for all using the bloom filters\n",
    "print( len(orthograph ) , set([p for p in orthograph.predicates() ]) )\n",
    "#get string ids by species\n",
    "pred = rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot')\n",
    "interactions = []\n",
    "for spec in prots_by_species:\n",
    "    stringids = [ s for prot in prots_by_species[spec] for s,p,o in orthograph.triples((None, pred , prot )) ]\n",
    "    #stringids = [ s.replace('https://string-db.org/network/' , '' ) for s in stringids ]\n",
    "    if len(stringids ) > 2 :\n",
    "        interactions += addfrombloom.check_allvall( objects = stringids , urlstring = 'https://string-db.org/network/' , filters = filters )\n",
    "[subg.add(t) for t in interactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#halelujah we have a graph with everything in it\n",
    "#serialize to turtle format\n",
    "v = subg.serialize(format=\"ttl\")\n",
    "with open('testgraph.ttl', 'w') as graphout:\n",
    "    graphout.write(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664371\n",
      "1664371\n"
     ]
    }
   ],
   "source": [
    "print(len(subg))\n",
    "readg = Graph()\n",
    "readg.parse('testgraph.ttl')\n",
    "print(len(readg))\n",
    "#we can save the subgraphs in rdf...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<https:omabrowser.orgomainfo'}\n",
      "{'<http:purl.uniprot.orgtaxonomy'}\n",
      "{'<http:purl.uniprot.orguniprot'}\n",
      "{'<https:string-db.orgnetwork'}\n",
      "ns5 51682 ns5 51682\n",
      "54076.0\n",
      "6069.0\n",
      "ns5 51682 ns3 2449\n",
      "3589.0\n",
      "5676.0\n",
      "59.0\n",
      "39312.0\n",
      "47221.0\n",
      "ns5 51682 ns4 70079\n",
      "72936.0\n",
      "69189.0\n",
      "7528.0\n",
      "59.0\n",
      "7372.0\n",
      "ns5 51682 ns6 57\n",
      "ns3 2449 ns5 51682\n",
      "5676.0\n",
      "47221.0\n",
      "ns3 2449 ns3 2449\n",
      "615.0\n",
      "2441.0\n",
      "ns3 2449 ns4 70079\n",
      "7063.0\n",
      "64366.0\n",
      "ns3 2449 ns6 57\n",
      "ns4 70079 ns5 51682\n",
      "5704.0\n",
      "49507.0\n",
      "ns4 70079 ns3 2449\n",
      "3311.0\n",
      "35741.0\n",
      "56.0\n",
      "68717.0\n",
      "7101.0\n",
      "ns4 70079 ns4 70079\n",
      "67302.0\n",
      "7091.0\n",
      "ns4 70079 ns6 57\n",
      "ns6 57 ns5 51682\n",
      "ns6 57 ns3 2449\n",
      "ns6 57 ns4 70079\n",
      "ns6 57 ns6 57\n",
      "149.0\n",
      "149.0\n",
      "149.0\n",
      "149.0\n",
      "HeteroData(\n",
      "  \u001b[1m(ns5, <protein1_orth_protein>, ns5)\u001b[0m={ edge_index=[2, 108152] },\n",
      "  \u001b[1m(ns5, <protein1_para_protein>, ns5)\u001b[0m={ edge_index=[2, 12126] },\n",
      "  \u001b[1m(ns5, <protein1_taxon_para>, ns3)\u001b[0m={ edge_index=[2, 7178] },\n",
      "  \u001b[1m(ns5, <para_protein_taxon_para>, ns3)\u001b[0m={ edge_index=[2, 11352] },\n",
      "  \u001b[1m(ns5, <protein1_taxon>, ns3)\u001b[0m={ edge_index=[2, 118] },\n",
      "  \u001b[1m(ns5, <protein1_taxon_orth>, ns3)\u001b[0m={ edge_index=[2, 78623] },\n",
      "  \u001b[1m(ns5, <orth_protein_taxon_orth>, ns3)\u001b[0m={ edge_index=[2, 94440] },\n",
      "  \u001b[1m(ns5, <protein1_orth_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 145871] },\n",
      "  \u001b[1m(ns5, <orth_protein_orth_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 138375] },\n",
      "  \u001b[1m(ns5, <protein1_para_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 15056] },\n",
      "  \u001b[1m(ns5, <protein1_protein1_uniprot>, ns4)\u001b[0m={ edge_index=[2, 118] },\n",
      "  \u001b[1m(ns5, <para_protein_para_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 14744] },\n",
      "  \u001b[1m(ns3, <taxon_para_protein>, ns5)\u001b[0m={ edge_index=[2, 11352] },\n",
      "  \u001b[1m(ns3, <taxon_orth_protein>, ns5)\u001b[0m={ edge_index=[2, 94441] },\n",
      "  \u001b[1m(ns3, <taxon_taxon_para>, ns3)\u001b[0m={ edge_index=[2, 1229] },\n",
      "  \u001b[1m(ns3, <taxon_taxon_orth>, ns3)\u001b[0m={ edge_index=[2, 4882] },\n",
      "  \u001b[1m(ns3, <taxon_para_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 14126] },\n",
      "  \u001b[1m(ns3, <taxon_orth_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 128731] },\n",
      "  \u001b[1m(ns4, <protein1_uniprot_para_protein>, ns5)\u001b[0m={ edge_index=[2, 11408] },\n",
      "  \u001b[1m(ns4, <protein1_uniprot_orth_protein>, ns5)\u001b[0m={ edge_index=[2, 99014] },\n",
      "  \u001b[1m(ns4, <protein1_uniprot_taxon_para>, ns3)\u001b[0m={ edge_index=[2, 6622] },\n",
      "  \u001b[1m(ns4, <protein1_uniprot_taxon_orth>, ns3)\u001b[0m={ edge_index=[2, 71480] },\n",
      "  \u001b[1m(ns4, <protein1_uniprot_taxon>, ns3)\u001b[0m={ edge_index=[2, 112] },\n",
      "  \u001b[1m(ns4, <orth_protein_uniprot_taxon_orth>, ns3)\u001b[0m={ edge_index=[2, 137431] },\n",
      "  \u001b[1m(ns4, <para_protein_uniprot_taxon_para>, ns3)\u001b[0m={ edge_index=[2, 14201] },\n",
      "  \u001b[1m(ns4, <protein1_uniprot_orth_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 134604] },\n",
      "  \u001b[1m(ns4, <protein1_uniprot_para_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 14175] },\n",
      "  \u001b[1m(ns6, <https://string-db.org/rdf/highest-confidence-cutoff>, ns6)\u001b[0m={ edge_index=[2, 262] },\n",
      "  \u001b[1m(ns6, <https://string-db.org/rdf/medium-confidence-cutoff>, ns6)\u001b[0m={ edge_index=[2, 262] },\n",
      "  \u001b[1m(ns6, <https://string-db.org/rdf/high-confidence-cutoff>, ns6)\u001b[0m={ edge_index=[2, 262] },\n",
      "  \u001b[1m(ns6, <https://string-db.org/rdf/any-confidence>, ns6)\u001b[0m={ edge_index=[2, 262] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create a new heterodata object\n",
    "from torch_geometric.data import HeteroData , Data\n",
    "import torch_geometric.utils \n",
    "from rdflib import RDF\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def sparse2pairs(sparsemat, matrows = None):\n",
    "    '''\n",
    "    This functino takes a sparse matrix and returns a list of pairs of the non zero entries\n",
    "    args:\n",
    "        sparsemat: a sparse matrix\n",
    "        matrows: a list of the matrix rows to keep\n",
    "    Returns:    \n",
    "        a list of pairs of the non zero entries\n",
    "    '''\n",
    "    if matrows :\n",
    "        sparsemat = sparsemat[matrows,:]\n",
    "        sparsemat = sparsemat[:,matrows]\n",
    "    sparsemat = scipy.sparse.find(sparsemat)\n",
    "    return np.vstack([sparsemat[0],sparsemat[1]])\n",
    "\n",
    "\n",
    "def test_heterograph(rdf_graph , verbose = True):\n",
    "    data = HeteroData()\n",
    "    # assign edge types from the predicate\n",
    "    edge_types = set([p for s,p,o in rdf_graph])\n",
    "    edge_types = {e:i for i,e in enumerate(edge_types)}\n",
    "\n",
    "    uris = {}\n",
    "    subtypes = {}\n",
    "    for sub, pred, obj in rdf_graph:\n",
    "        for o in (sub,obj):\n",
    "            if isinstance(o, URIRef):\n",
    "                uri_type = rdf_graph.qname(o).split(\":\")[0]  # get the namespace prefix\n",
    "                if uri_type not in uris:\n",
    "                    uris[uri_type] = []\n",
    "                    subtypes[uri_type] = set([])\n",
    "                uris[uri_type].append(o)\n",
    "                subtypes[uri_type].add( ''.join(o.n3().split('/')[0:-1] ) )\n",
    "    \n",
    "    if verbose == True:\n",
    "        for t in subtypes:\n",
    "            print(subtypes[t])\n",
    "            #compile the x data matrix for each subtype\n",
    "            \n",
    "    \n",
    "    node_index_by_type = { uritype : { n:i for i,n in enumerate( set(uris[uritype]) ) } for uritype in uris }\n",
    "    \n",
    "    #todo add the diff types of uris within each namespace as 1hot encoded for x attribute of each node\n",
    "    \n",
    "    \n",
    "    for t1,t2 in itertools.product(node_index_by_type,node_index_by_type):\n",
    "            rows = node_index_by_type[t1]\n",
    "            columns = node_index_by_type[t2]\n",
    "            if verbose == True:\n",
    "                print(t1,len(rows),t2, len(columns))\n",
    "                \n",
    "            for edge_type in edge_types:\n",
    "                \n",
    "                # create a dictionary of nodes\n",
    "                \n",
    "                triples =  [ (s,p,o) for s,p,o in rdf_graph.triples((None, edge_type, None))  if ( s in rows and o in columns )  ]\n",
    "                \n",
    "                if len(triples)>0:\n",
    "                    \n",
    "                    adj = scipy.sparse.lil_matrix((len(rows), len(columns)))\n",
    "                    \n",
    "                    for s,p,o in triples:    \n",
    "                        adj[rows[s], columns[o]] = 1\n",
    "                    \n",
    "                    \n",
    "                    if verbose == True:\n",
    "                        print(adj.sum())\n",
    "                        pass\n",
    "                    data[ t1 , p.n3() , t2 ].edge_index = torch.tensor( sparse2pairs(adj) ,  dtype=torch.long )\n",
    "                    #data[ t1 , p.n3() , t2 ].edge_index  = torch_geometric.utils.add_self_loops(data[ t1 , p.n3() , t2 ].edge_index , num_nodes = (len(rows), len(columns)) )\n",
    "                    data[ t1 , p.n3() , t2 ].edge_index = torch_geometric.utils.to_undirected(data[ t1 , p.n3() , t2 ].edge_index  )\n",
    "    return data\n",
    "data = test_heterograph(subg)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rdflib.term.URIRef('https://string-db.org/network/402676.B6JXG0'), rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot'), rdflib.term.Literal('http://purl.uniprot.org/uniprot/B6JXG0'))\n",
      "URIs:\n",
      "ns3 213839\n",
      "ns4 302906\n",
      "ns5 168253\n",
      "ns6 596\n",
      "\n",
      "Blank nodes:\n",
      "\n",
      "Literals:\n",
      "unknown 57\n",
      "2.2281651496887207\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 111\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 111\u001b[0m \u001b[43mseparate_graph_further\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt0)\n",
      "Cell \u001b[0;32mIn[54], line 72\u001b[0m, in \u001b[0;36mseparate_graph_further\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, p, o \u001b[38;5;129;01min\u001b[39;00m g:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, URIRef):\n\u001b[0;32m---> 72\u001b[0m         uri_type \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m uri_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m     74\u001b[0m             data[uri_type] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/work/FAC/FBM/DBC/cdessim2/default/dmoi/miniconda3/envs/ML2/lib/python3.10/site-packages/rdflib/graph.py:1045\u001b[0m, in \u001b[0;36mGraph.qname\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqname\u001b[39m(\u001b[38;5;28mself\u001b[39m, uri):\n\u001b[0;32m-> 1045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamespace_manager\u001b[49m\u001b[38;5;241m.\u001b[39mqname(uri)\n",
      "File \u001b[0;32m/work/FAC/FBM/DBC/cdessim2/default/dmoi/miniconda3/envs/ML2/lib/python3.10/site-packages/rdflib/graph.py:390\u001b[0m, in \u001b[0;36mGraph.namespace_manager\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21midentifier\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Node:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__identifier\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnamespace_manager\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamespaceManager:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03m    this graph's namespace-manager\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__namespace_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print((s,p,o))\n",
    "\n",
    "import time\n",
    "from rdflib import Graph, RDF, RDFS, OWL , Literal , BNode\n",
    "\n",
    "def separate_graph(g):\n",
    "    \n",
    "    # Create empty dictionaries for the different types of objects\n",
    "    uris = {}\n",
    "    bnodes = {}\n",
    "    literals = {}\n",
    "    # Iterate over all triples in the graph\n",
    "    for s, p, o in g:\n",
    "        if isinstance(o, URIRef):\n",
    "            uri_type = g.qname(o).split(\":\")[0]  # get the namespace prefix\n",
    "            if uri_type not in uris:\n",
    "                uris[uri_type] = []\n",
    "            uris[uri_type].append(o)\n",
    "\n",
    "        elif isinstance(o, BNode):\n",
    "            if o not in bnodes:\n",
    "                bnodes[o] = []\n",
    "\n",
    "            # Iterate over all triples that have the BNode as a subject\n",
    "            for s2, p2, o2 in g.triples((o, None, None)):\n",
    "                bnodes[o].append((s2, p2, o2))\n",
    "\n",
    "        elif isinstance(o, Literal):\n",
    "            literal_type = None\n",
    "            if RDF.type in g[o]:\n",
    "                for t in g[o][RDF.type]:\n",
    "                    if t in [RDFS.Literal, OWL.DatatypeProperty]:\n",
    "                        continue\n",
    "                    if isinstance(t, URIRef):\n",
    "                        literal_type = g.qname(t).split(\":\")[0]  # get the namespace prefix\n",
    "                        break\n",
    "\n",
    "            if literal_type is None:\n",
    "                literal_type = \"unknown\"\n",
    "\n",
    "            if literal_type not in literals:\n",
    "                literals[literal_type] = []\n",
    "            literals[literal_type].append(o)\n",
    "\n",
    "    # Print out the results\n",
    "    print(\"URIs:\")\n",
    "    for uri_type, uris in uris.items():\n",
    "        print(uri_type, len(uris))\n",
    "\n",
    "    print(\"\\nBlank nodes:\")\n",
    "    for bnode, triples in bnodes.items():\n",
    "        print(bnode, len(triples))\n",
    "\n",
    "    print(\"\\nLiterals:\")\n",
    "    for literal_type, literals in literals.items():\n",
    "        print(literal_type, len(literals))\n",
    "t0 = time.time()\n",
    "separate_graph(subg)\n",
    "print(time.time()-t0)\n",
    "\n",
    "def separate_graph_further(g):\n",
    "\n",
    "\n",
    "    # Create empty dictionaries for the different types of objects\n",
    "    uris = {}\n",
    "    bnodes = {}\n",
    "    literals = {}\n",
    "\n",
    "    # Iterate over all triples in the graph\n",
    "    for s, p, o in g:\n",
    "        if isinstance(o, URIRef):\n",
    "            uri_type = g.qname(o)\n",
    "            if uri_type not in data:\n",
    "                data[uri_type] = {}\n",
    "            if RDF.type in g[o]:\n",
    "                for t in g[o][RDF.type]:\n",
    "                    if t in [RDFS.Resource, OWL.Thing]:\n",
    "                        continue\n",
    "                    if isinstance(t, URIRef):\n",
    "                        type_name = g.qname(t)\n",
    "                        if type_name not in data[uri_type]:\n",
    "                            data[uri_type][type_name] = []\n",
    "                        data[uri_type][type_name].append(o)\n",
    "        else:\n",
    "            if isinstance(o, Literal):\n",
    "                literal_type = None\n",
    "                if RDF.type in g[o]:\n",
    "                    for t in g[o][RDF.type]:\n",
    "                        if t in [RDFS.Literal, OWL.DatatypeProperty]:\n",
    "                            continue\n",
    "                        if isinstance(t, URIRef):\n",
    "                            literal_type = g.qname(t)\n",
    "                            break\n",
    "\n",
    "                if literal_type is None:\n",
    "                    literal_type = \"unknown\"\n",
    "\n",
    "                if literal_type not in data:\n",
    "                    data[literal_type] = []\n",
    "                data[literal_type].append(o)\n",
    "\n",
    "    # Print out the results\n",
    "    for uri_type, types in data.items():\n",
    "        print(f\"Namespace: {uri_type}\")\n",
    "        for type_name, uris in types.items():\n",
    "            print(f\"  Type: {type_name}\")\n",
    "            print(f\"    URIs: {len(uris)}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        \n",
    "#too slow\n",
    "t0 = time.time()\n",
    "separate_graph_further(subg)\n",
    "print(time.time()-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = rdflib.extras.external_graph_libs.rdflib_to_networkx_multidigraph( subg , lambda s, p, o: {'data':{'key':p  , 'weight':1} } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example usage\n",
    "uniprot_id = \"http://purl.uniprot.org/uniprot/A0A3B5R6M3\" \n",
    "serverurl = '\n",
    "results =  map2string_fast.map2string_SPARQL(uniprot_id , serverurl = )\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [ p for p in rg.predicates( unique = True)]\n",
    "red = colour.Color('red')\n",
    "blue = colour.Color('blue')\n",
    "c = [ c.hex_l for c in  list(red.range_to(blue, len(preds))) ]\n",
    "colors = { p:c[i] for i,p in enumerate(preds)}\n",
    "delta = 2/len(preds)\n",
    "curve = { p:delta*i for i,p in enumerate(preds) }\n",
    "style = itertools.cycle([ '-', '--' ])\n",
    "line_style = { p:next(style) for p in preds }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.circular_layout( G )\n",
    "f = plt.figure()\n",
    "f.set_figwidth(15)\n",
    "f.set_figheight(15)\n",
    "plt.plot()\n",
    "#plot the whole mess\n",
    "ax = plt.gca()\n",
    "for e in G.edges(data = True):\n",
    "    ax.annotate(\"\",\n",
    "                xy=pos[e[0]], xycoords='data',\n",
    "                xytext=pos[e[1]], textcoords='data',\n",
    "                arrowprops=dict(arrowstyle=\"-\", color=colors[e[2]['data']['key']],\n",
    "                                shrinkA=5, shrinkB=5, lw = e[2]['data']['weight'], ls = line_style[e[2]['data']['key']],\n",
    "                                patchA=None, patchB=None, alpha = e[2]['data']['weight'],\n",
    "                                connectionstyle=\"arc3,rad=rrr\".replace('rrr',str(0.3*curve[e[2]['data']['key']])\n",
    "                                ),\n",
    "                                ),\n",
    "                )\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color = 'b', node_size = 150, alpha = .5)\n",
    "labels=nx.draw_networkx_labels(G , pos = pos , font_size= 15 , font_color='w')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map string neighbours to OMA entries\n",
    "\n",
    "#jump a few steps in HOGs\n",
    "\n",
    "#fish for STRING interactions in other species\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
