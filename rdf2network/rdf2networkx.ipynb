{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sZJA7QRc-lnW"
   },
   "outputs": [],
   "source": [
    "# Install required packages in the current Jupyter kernel\n",
    "# Uncomment the following lines if you need to install these libraries\n",
    "# If you run into permission issues, try with the --user option\n",
    "#import sys\n",
    "#!pip install -q rdflib networkx matplotlib\n",
    "#!{sys.executable} -m pip install rdflib networkx matplotlib pandas stringdb --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sampler\n",
    "import grabhogs_sparql\n",
    "import map2string_fast\n",
    "import addfrombloom\n",
    "import rdflib\n",
    "import SPARQLWrapper\n",
    "import colour\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aVA-JNpI-lna",
    "outputId": "a418ca78-5317-4b62-9367-642d64e2c709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdflib Graph loaded successfully with 2620310 triples\n",
      "rdflib Graph loaded successfully with 14559 triples\n"
     ]
    }
   ],
   "source": [
    "datapath = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.links.rdf.v11.5/402676.protein.links.rdf.v11.5.txt.gz'\n",
    "# RDF graph loading\n",
    "rg = sampler.load_graph(datapath)\n",
    "\n",
    "datapath2 = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.info.rdf.v11.5/402676.protein.info.rdf.v11.5.txt.gz'\n",
    "# RDF graph loading\n",
    "rg_info  = sampler.load_graph(datapath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831\n"
     ]
    }
   ],
   "source": [
    "links = '/work/FAC/FBM/DBC/cdessim2/default/dmoi/datasets/STRING/rdf/protein.links.rdf.v11.5/*.protein.links.rdf.v11.5.txt.gz'\n",
    "linkfiles = glob.glob(links)\n",
    "linkfiles = { l:{ 'links':l , 'info':l.replace('protein.links' , 'protein.info' ) } for l in linkfiles}\n",
    "print(len(linkfiles ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://string-db.org/network/402676.B6JY50\n"
     ]
    }
   ],
   "source": [
    "subjs = rg.subjects( unique = True)\n",
    "seed = next(subjs)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 699\n",
      "{rdflib.term.URIRef('https://string-db.org/rdf/medium-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/highest-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/high-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/any-confidence')}\n",
      "rdflib Graph sampled successfully with 544 triples\n"
     ]
    }
   ],
   "source": [
    "subg = sampler.sample( rg = rg , seed = seed,  layer_limit= 2 , sample_run = 20 )\n",
    "print(set([p for p in subg.predicates()]))\n",
    "print(\"rdflib Graph sampled successfully with {} triples\".format(len(subg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aVA-JNpI-lna",
    "outputId": "a418ca78-5317-4b62-9367-642d64e2c709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "92\n",
      "rdflib Graph annotated successfully with 636 triples\n",
      "{rdflib.term.URIRef('https://string-db.org/rdf/medium-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/highest-confidence-cutoff'), rdflib.term.URIRef('https://string-db.org/rdf/any-confidence'), rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot'), rdflib.term.URIRef('https://string-db.org/rdf/high-confidence-cutoff')}\n",
      "https://string-db.org/network/402676.B6K7A4 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K7A4\n",
      "https://string-db.org/network/402676.B6JX35 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JX35\n",
      "https://string-db.org/network/402676.B6JVM6 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JVM6\n",
      "https://string-db.org/network/402676.B6K6W0 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K6W0\n",
      "https://string-db.org/network/402676.B6JY50 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JY50\n",
      "https://string-db.org/network/402676.B6JXP3 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JXP3\n",
      "https://string-db.org/network/402676.B6K241 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K241\n",
      "https://string-db.org/network/402676.B6K3G1 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6K3G1\n",
      "https://string-db.org/network/402676.B6JWP5 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JWP5\n",
      "https://string-db.org/network/402676.B6JYN2 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JYN2\n",
      "https://string-db.org/network/402676.B6JXJ4 http://purl.org/lscr#xrefUniprot http://purl.uniprot.org/uniprot/B6JXJ4\n"
     ]
    }
   ],
   "source": [
    "subg = sampler.add_xrefs( rg_info , subg )\n",
    "print(\"rdflib Graph annotated successfully with {} triples\".format(len(subg)))\n",
    "print(set([p for p in subg.predicates()]))\n",
    "cross_ref = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\")\n",
    "i = 0 \n",
    "for s,p,o in subg.triples((None, cross_ref, None)):\n",
    "    print(s,p,o)\n",
    "    i+= 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proteins_by_species , results_subj_para , results_subj_ortho  = grabhogs_sparql.grab_hogs( subg , cross_ref = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results_subj_ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for 184 SPARQL queries: 83.47040796279907 seconds (multiple batch calls in: 0 cases)\n",
      "Num errors: 1\n"
     ]
    }
   ],
   "source": [
    "orthograph =  grabhogs_sparql.grab_hogs_graph( subg , cross_ref , sparql_endpoint= None\n",
    "            , USE_CASE = 1 , verbose = True , cross_ref_prop = rdflib.term.URIRef(\"http://purl.org/lscr#xrefUniprot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdflib Graph annotated successfully with 1306257 triples\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, URIRef\n",
    "print(\"rdflib Graph annotated successfully with {} triples\".format(len(orthograph)))\n",
    "#get all species\n",
    "taxa = [ 'protein1_uniprot_taxon_orth' , 'protein1_uniprot_taxon_para']\n",
    "species = set( [ o for t in taxa  for s,p,o in orthograph.triples((None, URIRef(t), None))  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the results for that species\n",
    "taxa = [ 'orth_protein_uniprot_taxon_orth' , 'para_protein_uniprot_taxon_para']\n",
    "#get all proteins for each species\n",
    "prots_by_species = { spec: set([s  for s,p,o in orthograph.triples((None, URIRef(t), spec ))]) for t in taxa for spec in species  }\n",
    "prots_by_species = { spec:prots_by_species[spec] for spec in prots_by_species if len(prots_by_species[spec])   }\n",
    "prots_by_species = { spec:[ p.replace('http://purl.uniprot.org/uniprot/' , '' ) for p in prots_by_species[spec] ] for spec in prots_by_species }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29059\n"
     ]
    }
   ],
   "source": [
    "server = 'dna076'\n",
    "ortho_xrefgraph = map2string_fast.mapall(prots_by_species , serverurl= \"http://\"+server+\":3030/string_fuseki/sparql\" , retgraph = True)\n",
    "print(len(ortho_xrefgraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthograph += ortho_xrefgraph\n",
    "subg += orthograph\n",
    "#we have interactions for one species and ortho info to all others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = addfrombloom.load_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1335316 {rdflib.term.URIRef('protein1_uniprot_para_protein_uniprot'), rdflib.term.URIRef('taxon_taxon_para'), rdflib.term.URIRef('taxon_para_protein_uniprot'), rdflib.term.URIRef('protein1_orth_protein'), rdflib.term.URIRef('protein1_taxon'), rdflib.term.URIRef('taxon_orth_protein'), rdflib.term.URIRef('para_protein_taxon_para'), rdflib.term.URIRef('protein1_uniprot_orth_protein_uniprot'), rdflib.term.URIRef('taxon_taxon_orth'), rdflib.term.URIRef('orth_protein_uniprot_taxon_orth'), rdflib.term.URIRef('protein1_taxon_para'), rdflib.term.URIRef('protein1_para_protein_uniprot'), rdflib.term.URIRef('orth_protein_taxon_orth'), rdflib.term.URIRef('para_protein_uniprot_taxon_para'), rdflib.term.URIRef('protein1_uniprot_para_protein'), rdflib.term.URIRef('protein1_taxon_orth'), rdflib.term.URIRef('protein1_uniprot_taxon_para'), rdflib.term.URIRef('protein1_orth_protein_uniprot'), rdflib.term.URIRef('taxon_orth_protein_uniprot'), rdflib.term.URIRef('protein1_uniprot_orth_protein'), rdflib.term.URIRef('protein1_protein1_uniprot'), rdflib.term.URIRef('taxon_para_protein'), rdflib.term.URIRef('orth_protein_orth_protein_uniprot'), rdflib.term.URIRef('protein1_para_protein'), rdflib.term.URIRef('protein1_uniprot_taxon_orth'), rdflib.term.URIRef('para_protein_para_protein_uniprot'), rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot'), rdflib.term.URIRef('protein1_uniprot_taxon')}\n",
      "http://purl.uniprot.org/taxonomy/73868 ['73868.A0A1Y3N8N6', '73868.A0A1Y3N8B6', '73868.A0A1Y3N1A5', '73868.A0A1Y3MZU9', '73868.A0A1Y3NJS3', '73868.A0A1Y3MMN6', '73868.A0A1Y3N8J8', '73868.A0A1Y3NFZ8', '73868.A0A1Y3N9R0', '73868.A0A1Y3N667'] 841\n",
      "http://purl.uniprot.org/taxonomy/9615 ['9615.ENSCAFP00000025621', '9615.ENSCAFP00000043669', '9615.ENSCAFP00000042881', '9615.ENSCAFP00000024805', '9615.ENSCAFP00000023411', '9615.ENSCAFP00000064006', '9615.ENSCAFP00000050877', '9615.ENSCAFP00000023207', '9615.ENSCAFP00000022281', '9615.ENSCAFP00000037025'] 902\n",
      "http://purl.uniprot.org/taxonomy/5627 ['5627.A0A1C7LQC8', '5627.A0A1C7M7N6', '5627.A0A1C7MDU8', '5627.A0A1C7MR90', '5627.A0A1C7MGV8', '5627.A0A1C7MWR4', '5627.A0A1C7LVJ6', '5627.A0A1C7MBP2', '5627.A0A1C7LWJ6', '5627.A0A1C7MEF9'] 1800\n",
      "http://purl.uniprot.org/taxonomy/13333 ['13333.ERM99458', '13333.ERN19945', '13333.ERN11512', '13333.ERN15972', '13333.ERN13620', '13333.ERN18094', '13333.ERN06281'] 1814\n",
      "http://purl.uniprot.org/taxonomy/413071 ['413071.G9NBQ9', '413071.G9MGF7', '413071.G9MJS0', '413071.G9N0F9', '413071.G9MVI3', '413071.G9MKJ4', '413071.G9N080', '413071.G9MF15', '413071.G9MRC4', '413071.G9MZ57'] 3002\n",
      "http://purl.uniprot.org/taxonomy/4955 ['4955.A0A1G4MI25', '4955.A0A1G4MB00', '4955.A0A1G4MEF0', '4955.A0A1G4ME38', '4955.A0A1G4M9N2', '4955.A0A1G4MH54', '4955.A0A1G4M7B0', '4955.A0A1G4M7C5', '4955.A0A1G4MJM3', '4955.A0A1G4MJY3'] 3708\n",
      "http://purl.uniprot.org/taxonomy/212818 ['212818.A0A0D1ZF22', '212818.A0A0D1Z952', '212818.A0A0D1XKK9', '212818.A0A0D1ZZK3', '212818.A0A0D1ZC62', '212818.A0A0D1Y000', '212818.A0A0D1Z7D2', '212818.A0A0D1WSN6', '212818.A0A0D2A313', '212818.A0A0D1Z024'] 4708\n",
      "http://purl.uniprot.org/taxonomy/3880 ['3880.AES78227', '3880.AES90548', '3880.AES65351', '3880.AES78087', '3880.AES77883', '3880.AES81705', '3880.AES78159', '3880.AES78058', '3880.AES78190', '3880.AES65352'] 4829\n",
      "http://purl.uniprot.org/taxonomy/771870 ['771870.F7W072', '771870.F7VN71', '771870.F7VN95', '771870.F7W3Q1', '771870.F7VKE1', '771870.F7VN58', '771870.F7W6R6', '771870.F7W1W7', '771870.F7VSQ4', '771870.F7VVW3'] 5940\n",
      "http://purl.uniprot.org/taxonomy/49451 ['49451.A0A1J6JYF9', '49451.A0A1J6I503', '49451.A0A1J6IHW2', '49451.A0A1J6KBD9', '49451.A0A1J6IU35', '49451.A0A1J6HXP5', '49451.A0A1J6I1V3', '49451.A0A1J6J7G2', '49451.A0A314KM92', '49451.A0A1J6KEP4'] 5957\n",
      "http://purl.uniprot.org/taxonomy/4536 ['4536.ONIVA02G36410.1', '4536.ONIVA06G15280.1', '4536.ONIVA01G41500.1', '4536.ONIVA12G07210.1', '4536.ONIVA05G11020.1', '4536.ONIVA08G13200.1', '4536.ONIVA07G03760.1', '4536.ONIVA09G15520.1', '4536.ONIVA03G01190.1', '4536.ONIVA07G18430.1'] 5983\n",
      "http://purl.uniprot.org/taxonomy/103827 ['103827.A0A0N5D8Q9', '103827.A0A0N5D4B4', '103827.A0A0N5D1K2', '103827.A0A0N5CQ79', '103827.A0A0N5CMK8', '103827.A0A0N5CMG9', '103827.A0A0N5CYK0', '103827.A0A0N5CZK7', '103827.A0A0N5CRS6', '103827.A0A0N5CNT0'] 6583\n",
      "http://purl.uniprot.org/taxonomy/51031 ['51031.W2TFF2', '51031.W2SQI7', '51031.W2TG77', '51031.W2TVP7', '51031.W2TK29', '51031.W2TMJ3', '51031.W2T7N6', '51031.W2SZ09', '51031.W2TS74', '51031.W2TT82'] 7033\n",
      "http://purl.uniprot.org/taxonomy/578459 ['578459.A0A0P9ENI3', '578459.A0A194S1N6', '578459.A0A194S9E5', '578459.A0A0P9GWU4', '578459.A0A194SDV9', '578459.A0A194SFE5', '578459.A0A0P9H1L4', '578459.A0A0P9ENU6', '578459.A0A194S592', '578459.A0A194SCR4'] 8293\n",
      "http://purl.uniprot.org/taxonomy/332952 ['332952.B8NV28', '332952.B8NH37', '332952.B8NKG8', '332952.B8NKB7', '332952.B8NRK5', '332952.B8NYQ1', '332952.B8NB87', '332952.B8N8Q1', '332952.B8N3W1', '332952.B8N3S2'] 9399\n"
     ]
    }
   ],
   "source": [
    "#lets add the interactions for all using the bloom filters\n",
    "print( len(orthograph ) , set([p for p in orthograph.predicates() ]) )\n",
    "#get string ids by species\n",
    "pred = rdflib.term.URIRef('http://purl.org/lscr#xrefUniprot')\n",
    "interactions = []\n",
    "for spec in prots_by_species:\n",
    "    stringids = [ s for prot in prots_by_species[spec] for s,p,o in orthograph.triples((None, pred , URIRef('http://purl.uniprot.org/uniprot/'+prot) )) ]\n",
    "    stringids = [ s.replace('https://string-db.org/network/' , '' ) for s in stringids ]\n",
    "    if len(stringids ) > 2 :\n",
    "        interactions += addfrombloom.check_allvall( objects = stringids , urlstring = 'https://string-db.org/network/' , filters = filters )\n",
    "        print(spec,stringids[0:10], len(interactions))\n",
    "[subg.add(t) for t in interactions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#halelujah we have a graph with everything in it\n",
    "#serialize to turtle format\n",
    "v = subg.serialize(format=\"ttl\")\n",
    "with open('testgraph.ttl', 'w') as graphout:\n",
    "    graphout.write(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readg = rdflib.Graph()\n",
    "readg.parse('testgraph.ttl')\n",
    "print(len(readg))\n",
    "#we can save the subgraphs in rdf..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns3 31567 ns3 31567\n",
      "3029.0\n",
      "29643.0\n",
      "ns3 31567 ns4 38582\n",
      "36536.0\n",
      "3275.0\n",
      "37881.0\n",
      "3384.0\n",
      "36.0\n",
      "ns3 31567 ns5 2450\n",
      "36.0\n",
      "2886.0\n",
      "28647.0\n",
      "24844.0\n",
      "1696.0\n",
      "ns3 31567 ns6 42\n",
      "ns4 38582 ns3 31567\n",
      "2886.0\n",
      "28647.0\n",
      "ns4 38582 ns4 38582\n",
      "3229.0\n",
      "35319.0\n",
      "ns4 38582 ns5 2450\n",
      "24162.0\n",
      "3243.0\n",
      "37198.0\n",
      "1642.0\n",
      "35.0\n",
      "ns4 38582 ns6 42\n",
      "ns5 2450 ns3 31567\n",
      "28647.0\n",
      "2886.0\n",
      "ns5 2450 ns4 38582\n",
      "3229.0\n",
      "35319.0\n",
      "ns5 2450 ns5 2450\n",
      "535.0\n",
      "2448.0\n",
      "ns5 2450 ns6 42\n",
      "ns6 42 ns3 31567\n",
      "ns6 42 ns4 38582\n",
      "ns6 42 ns5 2450\n",
      "ns6 42 ns6 42\n",
      "120.0\n",
      "120.0\n",
      "120.0\n",
      "120.0\n",
      "HeteroData(\n",
      "  \u001b[1mns3\u001b[0m={ x=[267631, 1] },\n",
      "  \u001b[1mns4\u001b[0m={ x=[294569, 1] },\n",
      "  \u001b[1mns5\u001b[0m={ x=[200436, 1] },\n",
      "  \u001b[1mns6\u001b[0m={ x=[1010, 1] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_para_protein>, ns3)\u001b[0m={ edge_index=[2] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_orth_protein>, ns3)\u001b[0m={ edge_index=[2] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_orth_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 36536] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/para_protein_para_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 3275] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/orth_protein_orth_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 37881] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_para_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 3384] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_protein1_uniprot>, ns4)\u001b[0m={ edge_index=[2, 36] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_taxon>, ns5)\u001b[0m={ edge_index=[2, 36] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/para_protein_taxon_para>, ns5)\u001b[0m={ edge_index=[2, 2886] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/orth_protein_taxon_orth>, ns5)\u001b[0m={ edge_index=[2, 28647] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_taxon_orth>, ns5)\u001b[0m={ edge_index=[2, 24844] },\n",
      "  \u001b[1m(ns3, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_taxon_para>, ns5)\u001b[0m={ edge_index=[2, 1696] },\n",
      "  \u001b[1m(ns4, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_uniprot_para_protein>, ns3)\u001b[0m={ edge_index=[2, 2886] },\n",
      "  \u001b[1m(ns4, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_uniprot_orth_protein>, ns3)\u001b[0m={ edge_index=[2, 28647] },\n",
      "  \u001b[1m(ns4, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_uniprot_para_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2] },\n",
      "  \u001b[1m(ns4, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_uniprot_orth_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2] },\n",
      "  \u001b[1m(ns4, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_uniprot_taxon_orth>, ns5)\u001b[0m={ edge_index=[2, 24162] },\n",
      "  \u001b[1m(ns4, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/para_protein_uniprot_taxon_para>, ns5)\u001b[0m={ edge_index=[2, 3243] },\n",
      "  \u001b[1m(ns4, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/orth_protein_uniprot_taxon_orth>, ns5)\u001b[0m={ edge_index=[2, 37198] },\n",
      "  \u001b[1m(ns4, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_uniprot_taxon_para>, ns5)\u001b[0m={ edge_index=[2, 1642] },\n",
      "  \u001b[1m(ns4, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/protein1_uniprot_taxon>, ns5)\u001b[0m={ edge_index=[2, 35] },\n",
      "  \u001b[1m(ns5, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/taxon_orth_protein>, ns3)\u001b[0m={ edge_index=[2, 28647] },\n",
      "  \u001b[1m(ns5, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/taxon_para_protein>, ns3)\u001b[0m={ edge_index=[2, 2886] },\n",
      "  \u001b[1m(ns5, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/taxon_para_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 3229] },\n",
      "  \u001b[1m(ns5, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/taxon_orth_protein_uniprot>, ns4)\u001b[0m={ edge_index=[2, 35319] },\n",
      "  \u001b[1m(ns5, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/taxon_taxon_para>, ns5)\u001b[0m={ edge_index=[2] },\n",
      "  \u001b[1m(ns5, <file:///work/FAC/FBM/DBC/cdessim2/default/dmoi/projects/RDF_Graphnet/rdf2network/taxon_taxon_orth>, ns5)\u001b[0m={ edge_index=[2] },\n",
      "  \u001b[1m(ns6, <https://string-db.org/rdf/high-confidence-cutoff>, ns6)\u001b[0m={ edge_index=[2] },\n",
      "  \u001b[1m(ns6, <https://string-db.org/rdf/medium-confidence-cutoff>, ns6)\u001b[0m={ edge_index=[2] },\n",
      "  \u001b[1m(ns6, <https://string-db.org/rdf/highest-confidence-cutoff>, ns6)\u001b[0m={ edge_index=[2] },\n",
      "  \u001b[1m(ns6, <https://string-db.org/rdf/any-confidence>, ns6)\u001b[0m={ edge_index=[2] }\n",
      ")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 77\u001b[0m\n\u001b[1;32m     75\u001b[0m     data \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mToUndirected()(data)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m---> 77\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtest_heterograph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreadg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n",
      "Cell \u001b[0;32mIn[8], line 75\u001b[0m, in \u001b[0;36mtest_heterograph\u001b[0;34m(rdf_graph, verbose)\u001b[0m\n\u001b[1;32m     73\u001b[0m                     data[ t1 , p\u001b[38;5;241m.\u001b[39mn3() , t2 ]\u001b[38;5;241m.\u001b[39medge_index  \u001b[38;5;241m=\u001b[39m torch_geometric\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39madd_self_loops(data[ t1 , p\u001b[38;5;241m.\u001b[39mn3() , t2 ]\u001b[38;5;241m.\u001b[39medge_index )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[0;32m---> 75\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToUndirected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/work/FAC/FBM/DBC/cdessim2/default/dmoi/miniconda3/envs/ML2/lib/python3.10/site-packages/torch_geometric/transforms/to_undirected.py:45\u001b[0m, in \u001b[0;36mToUndirected.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m store:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m nnz \u001b[38;5;241m=\u001b[39m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, HeteroData) \u001b[38;5;129;01mand\u001b[39;00m (store\u001b[38;5;241m.\u001b[39mis_bipartite()\n\u001b[1;32m     48\u001b[0m                                      \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge):\n\u001b[1;32m     49\u001b[0m     src, rel, dst \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39m_key\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# create a new heterodata object\n",
    "from rdflib import URIRef\n",
    "from torch_geometric.data import HeteroData , Data\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.utils \n",
    "from rdflib import RDF\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import torch\n",
    "\n",
    "def sparse2pairs(sparsemat, matrows = None):\n",
    "    '''\n",
    "    This functino takes a sparse matrix and returns a list of pairs of the non zero entries\n",
    "    args:\n",
    "        sparsemat: a sparse matrix\n",
    "        matrows: a list of the matrix rows to keep\n",
    "    Returns:    \n",
    "        a list of pairs of the non zero entries\n",
    "    '''\n",
    "    if matrows :\n",
    "        sparsemat = sparsemat[matrows,:]\n",
    "        sparsemat = sparsemat[:,matrows]\n",
    "    sparsemat = scipy.sparse.find(sparsemat)\n",
    "    return np.vstack([sparsemat[0],sparsemat[1]])\n",
    "\n",
    "def test_heterograph(rdf_graph , verbose = True):\n",
    "    data = HeteroData()\n",
    "    # assign edge types from the predicate\n",
    "    edge_types = set([p for s,p,o in rdf_graph])\n",
    "    edge_types = {e:i for i,e in enumerate(edge_types)}\n",
    "    uris = {}\n",
    "    subtypes = {}\n",
    "    for sub, pred, obj in rdf_graph:\n",
    "        for o in (sub,obj):\n",
    "            if isinstance(o, URIRef):\n",
    "                uri_type = rdf_graph.qname(o).split(\":\")[0]  # get the namespace prefix\n",
    "                if uri_type not in uris:\n",
    "                    uris[uri_type] = []\n",
    "                    subtypes[uri_type] = set([])\n",
    "                uris[uri_type].append(o)\n",
    "                subtypes[uri_type].add( ''.join(o.n3().split('/')[0:-1] )  )\n",
    "    if verbose == True:\n",
    "        for t in subtypes:\n",
    "            #compile the x data matrix for each subtype\n",
    "            subtype_dict = { ty:i for i,ty in enumerate(subtypes[t])}\n",
    "            indices = [ subtype_dict[''.join(o.n3().split('/')[0:-1])] for o in uris[t] ]\n",
    "            x= np.zeros( (len(uris[t]), len(subtype_dict)))\n",
    "            x[:,indices] = 1\n",
    "            #for now this is 1hot for subtype\n",
    "            #add some more descriptive data here if you have it\n",
    "            data[t].x = torch.tensor(x , dtype=torch.float )\n",
    "    node_index_by_type = { uritype : { n:i for i,n in enumerate( set(uris[uritype]) ) } for uritype in uris }\n",
    "    #todo add the diff types of uris within each namespace as 1hot encoded for x attribute of each node\n",
    "    for t1,t2 in itertools.product(node_index_by_type,node_index_by_type):\n",
    "            rows = node_index_by_type[t1]\n",
    "            columns = node_index_by_type[t2]\n",
    "            if verbose == True:\n",
    "                print(t1,len(rows),t2, len(columns)) \n",
    "            for edge_type in edge_types:\n",
    "                # create a dictionary of nodes\n",
    "                triples =  [ (s,p,o) for s,p,o in rdf_graph.triples((None, edge_type, None))  if ( s in rows and o in columns )  ]\n",
    "                if len(triples)>0:\n",
    "                    adj = scipy.sparse.lil_matrix((len(rows), len(columns)))\n",
    "                    for s,p,o in triples:    \n",
    "                        adj[rows[s], columns[o]] = 1\n",
    "                    if verbose == True:\n",
    "                        print(adj.sum())\n",
    "                        pass\n",
    "                    #between subgraphs\n",
    "                    data[ t1 , p.n3() , t2 ].edge_index = torch.tensor( sparse2pairs(adj) ,  dtype=torch.long )\n",
    "                    if t1 == t2:\n",
    "                        #within a subgraph of the same namespace\n",
    "                        data[ t1 , p.n3() , t2 ].edge_index  = torch_geometric.utils.add_self_loops(data[ t1 , p.n3() , t2 ].edge_index )\n",
    "    print(data)\n",
    "    data = T.ToUndirected()(data)\n",
    "    return data\n",
    "data = test_heterograph(readg)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a model\n",
    "import buildmodel\n",
    "model = buildmodel.HeteroGCN_linkpred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample edges\n",
    "# For this, we first split the set of edges into\n",
    "# training (80%), validation (10%), and testing edges (10%).\n",
    "# Across the training edges, we use 70% of edges for message passing,\n",
    "# and 30% of edges for supervision.\n",
    "# We further want to generate fixed negative edges for evaluation with a ratio of 2:1.\n",
    "# Negative edges during training will be generated on-the-fly.\n",
    "# We can leverage the `RandomLinkSplit()` transform for this from PyG:\n",
    "#HERE the only EDGE TYPE you would use for split would be (\"protein\", \"interacts\", \"protein\")\n",
    "# although the graph would also contain (\"protein\", \"isOrtho\", \"protein\")\n",
    "# maybe also species as a link?? or should it be a node feature\n",
    "\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,  # percentage of VALIDATION\n",
    "    num_test=0.1,  # percentage of TESTING\n",
    "    disjoint_train_ratio=0.3,  # this somehow has to do with the 30% we need for supervision\n",
    "    neg_sampling_ratio=2,  # TODO\n",
    "    add_negative_train_samples=True,  # TODO\n",
    "    edge_types=(\"user\", \"rates\", \"movie\"),\n",
    "    rev_edge_types=(\"movie\", \"rev_rates\", \"user\"), \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(\"Training data:\")\n",
    "print(\"==============\")\n",
    "print(train_data)\n",
    "print()\n",
    "print(\"Validation data:\")\n",
    "print(\"================\")\n",
    "print(val_data)\n",
    "\n",
    "print(train_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1))\n",
    "print(val_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1))\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].num_edges == 56469 \n",
    "#assert train_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 24201\n",
    "assert train_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 56469\n",
    "# No negative edges added:\n",
    "#assert train_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 1\n",
    "#assert train_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1\n",
    "\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].num_edges == 80670\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 30249\n",
    "assert val_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 80670\n",
    "# Negative edges with ratio 2:1:\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label.long().bincount().tolist() == [20166, 10083]\n",
    "\n",
    "\n",
    "\n",
    "# In the first hop, we sample at most 20 neighbors.\n",
    "# In the second hop, we sample at most 10 neighbors.\n",
    "# In addition, during training, we want to sample negative edges on-the-fly with\n",
    "# a ratio of 2:1.\n",
    "# We can make use of the `loader.LinkNeighborLoader` from PyG:\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Define seed edges:\n",
    "##Â HERE IS where you would basically train with both types of links, but then for testing you would only want to generate INTERACT\n",
    "edge_label_index = train_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,  # TODO\n",
    "    num_neighbors=[20, 10],  # TODO\n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    #edge_label=edge_label,\n",
    "    neg_sampling_ratio=2,  # TODO\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Inspect a sample:\n",
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)\n",
    "\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 3 * 128\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 0\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
